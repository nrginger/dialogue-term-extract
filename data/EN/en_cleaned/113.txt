The identification of semantically related words is an actual NL
P task. Most of the special lexicographic research in that area is focused on identifying synonymy, multiword expressions or hyperonymy-hyponymy relations. One special case of lexical relation extraction is modeling verb semantics using the information about the verb-noun compatibility. The information obtained from the verb-noun distribution model is then used in a wide range of NL
P tasks such as semantic-role labeling (), word sense disambiguation (, fact extraction, thesaurus building (, ), machine translation () and others. Modeling lexical relations between words can be done automatically by methods of collocation extraction.
Generally, the collocation extraction is a two-step process which includes candidate extraction and candidate ranking. A variety of methods are proposed for executing each of these steps. In particular, the candidate selection can be performed using either linear or syntactic text representation. In the first case, the words in the source texts are treated as consequent units, while the second model relies on syntactic representation in which units are connected non-linearly. Being more complex from a technical point of view, the latter method should result in noise reduction and higher recall due to the additional syntactic filtering. Our aim is to compare the collocation sets obtained by using these two candidate extraction methods in the same setting, and to analyze the differences between the results.
2. Background
2.1. Notion of collocation
The definition of â€œcollocationâ€ differs across linguistic traditions. From the theoretical point of view, collocation can be considered to be some kind of a â€œfixed phraseâ€, in a scale where fixed phrases are opposed to â€œfree phrasesâ€ (see a review). However, when it gets to practice, retrieving a particular theoretically predetermined class of phrases can become problematic. A more practical definition of collocation within the corpus linguistics paradigm will be â€œtwo or more lexical units that co-occur more often than would be expected by chanceâ€ . Statistically-based methods of collocation extraction ranks word pairs according to a certain measure of association, which evaluates Akinina Y. S., Kuznetsov I. O., Toldova S. Y.
chance of their occurrence. As a consequence a high rank can be obtained not only by fixed expressions such as ÑĞ»Ğ¾Ğ¼Ğ°Ñ‚ÑŒ Ğ³Ğ¾Ğ»Ğ¾Ğ²Ñƒ â€œrack oneâ€™/s brainsâ€, but by free word combinations such as ÑĞ»Ğ¾Ğ¼Ğ°Ñ‚ÑŒ Ñ€ÑƒĞºÑƒ â€œto break smbâ€™s handâ€. While the former is an idiom listed in a dictionary the meaning of the latter is compositional. However the noun Ñ€ÑƒĞºĞ° in the latter is a â€œtypicalâ€ argument for the verb ÑĞ»Ğ¾Ğ¼Ğ°Ñ‚ÑŒ. This type of word-combinations should be also taken into consideration for verb semantics modeling. Thus we use the term collocation for both types of word combinations discussed above.
2.2. Collocation candidate selection methods
Choosing the method of compiling lists of possible collocates is a crucial step in collocation extraction. The variety of methods can be roughly divided in two groups. The methods from the first group, which we refer to as window-based methods (e. g. , , , ), rely on linear word order model, in which the collocation candidates are extracted from a fixed-size window, and the distances correspond to the raw distance between two (or more) words as presented in the source document. Analyzing adjacent bigrams can be regarded as a particular case with window size of 1. Applying PO
S or pattern filters can be implemented as an approximation to syntactic structures (, ). The second group can be referred to as syntax-based methods (, , ). The methods from this group rely on syntactic structure instead of using the linear representation. The candidate list is generated based on syntactic relations. Both candidate selection methods have advantages and shortcomings. Window-based methods tend to extract additional noisy data and ignore the long-distance syntactical links (), but are easy to implement. Using the syntax-based methods makes it possible to filter out spurious examples in the nearest context and also access the distant collocates, which are invisible in the window-based linear representation (). The increase in precision comes at the cost of carefully describing all the syntactical constructions, in which two collocation candidates can occur.
2.3. Verb-noun collocation extraction
When it comes to verb-noun (V
N) collocations, the researchersâ€™ aim is usually to extract some specific, theoretically predetermined types of constructions (, , ). There is a particular interest among researchers for the task of V
N collocation extraction. The majority of the works are based on the combination of morphological pattern-based and statistically based methods (see French and Romanian, German, English and Romanian, German). For this method a high level of noise is reported (c. f. ). On the one hand, a certain amount of totally irrelevant V
N pairs were extracted by means of the method. The impact of syntactic structure on verb-noun collocation extraction On the other hand, the authors were looking for some particular types of collocations. For instance, subject+predicate collocations or combinations with circumstantial adjunct (, ) were out of the authorâ€™s interest. Therefore, the conclusion was that the syntactic information was required to detect such combinations (). The authors of claim that syntactic parsing is necessary to distinguish subject-verb from object-verb combinations. Indeed, applying syntactic filters over a parsed corpus in English allows getting statistical information from Subject-Verb
Object triples to accurately answer the questions about typical arguments, e. g. â€œ
What can you drink?â€ .
There are some works that focus on collocation extraction in Russian, but so far the main method has consisted of applying/comparing different word association measures over the lists of adjacent word units (e. g. , ). The experience of using syntax-based Word Sketches methodology presented in viability of this method for collocation search in Russian, but does not analyze Verb
Noun collocations in particular. The work presented in extracting verb lexical compatibility information in general (that is, not just fixed phrases, but typical free phrases as well), but it relies on a huge text corpus to bypass the syntactic parsing using a number of assumptions (such as â€œthe next noun phrase after a single verb most probably depends on itâ€). The authors of a good correlation between the high-frequency part of the list and the lists obtained with collocation methods.
To sum up, the majority of works on Verb
Noun collocations investigate the nouns that are involved in some particular types of verb-argument relations or Verb
Noun fixed Expressions (excluding Klyshinskij et al. 2010). In our research all the syntactically related to a verb noun are taken into consideration irrespective of their syntactic role (direct object, circumstantial N
P etc.).
3. Experiment
3.1. Setup
The goal of the experiment described below is to compare the verb-noun collocations extracted from a large corpus with and without use of syntactic information. The corpus was preprocessed with a tokenizer, a PO
S-tagger, a morphology analyzer and a syntactic parser. We use the Pointwise mutual information (PM
I) as a statistic measure for verb-noun collocation extraction. The two methods for collocation candidates extraction are used: the first one is a window-based bag of words method, the second one is based on the results of syntactic parsing.
The resulting collocation sets were grouped by verb and compared in order to evaluate the degree of correspondence between the extracted sets. The results of this comparison were then analyzed in detail, and several conclusions about the mismatching cases were made.
Akinina Y. S., Kuznetsov I. O., Toldova S. Y.
Corpus
In order to obtain sufficient amounts of initial data, a roughly 9 million word corpus of Russian newspaper texts was used1. The corpus consists of planarized random sentences sampled from various news articles published in the period from April 2011 to April 2012. This results in a certain lexical skewness, as the vocabulary, describing the events which have taken place in that period of time, influences the word distribution over the corpus. However, we believe that this factor can be disregarded, taking into account that the corpus was used to compare two automatic methods on the same dataset without use of any external data.
3.3. Preprocessing
The corpus has been preprocessed using a set of tools developed by S. Sharoff and J. Nivre (), which includes a tokenizer, a Tree
Tagger-based () part-of-speech tagger, a lemmatizer based on CST
Lemma (), and a Russian dependency parser model for the Malt
Parser () trained on SynTag
Rus syntactic corpus (). The preprocessed texts have been allocated in a relational database and indexed. The resulting dataset consists of tokens which are mapped to words; each word is assigned a set of morphological features and a lemma, and for each sentence a set of labeled dependency relations is fixed. S. Sharoff and J. Nivre report 95â€“97 % PO
S-tagger accuracy and an unlabeled attachment score of 88 (), which seems sufficient for our type of analysis, taking into account that we aim to extract statistically dependent word pairs from a large corpus, and the impact of accidental errors should be smoothed by the dataset size. Although the relation labels are available, they werenâ€™t used during the experiment, so all the dependency links were treated as unlabeled ones.
3.4. Collocation extraction
We have extracted collocations from the syntactically parsed corpus using two different strategies for obtaining the initial collocation candidate lists. Only finite verb forms were analyzed due to the fact, that the non-finite forms in Russian often lack some of the overtly expressed arguments, so taking these forms into account would require additional transformation and preprocessing steps.
The first candidate extraction strategy is to build potential collocate pairs by extracting unlabeled verb-noun dependency relations. In case of prepositional objects where the dependency relation points at a preposition, the preposition was skipped (see the collocation candidates Ñ€Ğ°ÑÑ‚Ğ¸ (â€˜grow upâ€™) â€” ĞĞ³Ğ°Ñ„Ğ¾Ğ½Ğ¾Ğ² (â€˜
Agafonovâ€™) 1 The corpus was collected by H. Christensen and is available on http://corpora.heliohost.org/
The impact of syntactic structure on verb-noun collocation extraction Ğ¸ Ñ€Ğ°ÑÑ‚Ğ¸ (â€˜grow upâ€™) â€” ÑĞµĞ¼ÑŒÑ (â€˜familyâ€™) in the example (1)). The total of 358,915 verbnoun pairs was obtained. We will refer to the collocations resulting from these pairs as syntax-based or dependency-based collocations.
(1) (â€˜
Agafonov grew up in a complete family with medium incomeâ€™)
The second strategy is to use a window-based approach. In order to estimate the appropriate window size, the distribution of distances between verbs and their dependent nouns was analyzed (see Fig. 1) and the window size of was selected as a result.
For every finite verb form in the corpus, we have extracted all the nouns found in the same sentence in the context of The non-word tokens such as punctuation and numbers were ignored. From all the extracted pairings, a collocation candidate list containing verb lemma, noun lemma and the collocation frequency was formed. 708,131 collocations were extracted using the bag-of-words strategy. We refer to the collocations obtained using this method as window-based collocations.
Akinina Y. S., Kuznetsov I. O., Toldova S. Y.
collocation candidates were ranked using the PM
I metric, which is defined asğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘(ğ‘¥ğ‘¥ğ‘¥ğ‘¥,ğ‘¦ğ‘¦ğ‘¦ğ‘¦) = logğ‘ƒğ‘ƒğ‘ƒğ‘ƒ(ğ‘¥ğ‘¥ğ‘¥ğ‘¥,ğ‘¦ğ‘¦ğ‘¦ğ‘¦)ğ‘ƒğ‘ƒğ‘ƒğ‘ƒ(ğ‘¥ğ‘¥ğ‘¥ğ‘¥) âˆ— ğ‘ƒğ‘ƒğ‘ƒğ‘ƒ(ğ‘¦ğ‘¦ğ‘¦ğ‘¦) ğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Š(ğ´ğ´ğ´ğ´;ğµğµğµğµ) = |ğ‘¥ğ‘¥ğ‘¥ğ‘¥ âˆˆ (ğ´ğ´ğ´ğ´ âˆ© ğµğµğµğµ)||ğ‘¥ğ‘¥ğ‘¥ğ‘¥ âˆˆ ğ´ğ´ğ´ğ´| ğ¹ğ¹ğ¹ğ¹1 =2 âˆ— ğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Š(ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘ğ‘ğ‘ğ‘ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤, ğ‘ ğ‘ ğ‘ ğ‘ ğ‘¦ğ‘¦ğ‘¦ğ‘¦ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘¥ğ‘¥ğ‘¥ğ‘¥) âˆ— ğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Š(ğ‘ ğ‘ ğ‘ ğ‘ ğ‘¦ğ‘¦ğ‘¦ğ‘¦ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘¥ğ‘¥ğ‘¥ğ‘¥,ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘ğ‘ğ‘ğ‘ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤)
ğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Š(ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘ğ‘ğ‘ğ‘ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤, ğ‘ ğ‘ ğ‘ ğ‘ ğ‘¦ğ‘¦ğ‘¦ğ‘¦ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘¥ğ‘¥ğ‘¥ğ‘¥) + ğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Š(ğ‘ ğ‘ ğ‘ ğ‘ ğ‘¦ğ‘¦ğ‘¦ğ‘¦ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘¥ğ‘¥ğ‘¥ğ‘¥,ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘ğ‘ğ‘ğ‘ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤) PM
I as a word association measure has several drawbacks, among them an overrating of infrequent combinations and a poor accordance with expert collocation lists evaluation (). The first is usually handled by establishing frequency cutoff thresholds. In our experiment only the combinations containing verbs with total raw frequency more than 100 and nouns with total raw frequency more than 10 were analyzed. As for the combination frequency threshold itself, we have found out that the cutoff value of 10 filters out too many combinations, resulting in very short final sets as compared to the sets obtained using lower cutoff threshold. Lower cutoff thresholds introduce some noisy data but also increase the recall, e. g.:(2) ÑĞ»Ğ¾Ğ¼Ğ°Ñ‚ÑŒ (â€˜breakâ€™) Ñ10wc10 syntax, window: Ñ€ÑƒĞºĞ° (â€˜armâ€™), Ğ½Ğ¾Ğ³Ğ° (â€˜legâ€™) Ñ5wc5 syntax, window: Ğ½Ğ¾Ğ³Ğ° (â€˜legâ€™), Ğ½Ğ¾Ñ (â€˜noseâ€™), Ñ€ĞµĞ±Ñ€Ğ¾ (â€˜ribâ€™), Ñ€ÑƒĞºĞ° (â€˜armâ€™) Ñ2wc2 syntax: Ğ½Ğ¾Ğ³Ğ° (â€˜legâ€™), Ğ½Ğ¾Ñ (â€˜noseâ€™), Ñ€ĞµĞ±Ñ€Ğ¾ (â€˜ribâ€™), Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ (â€˜resultâ€™), Ñ‡ĞµĞ»ÑÑÑ‚ÑŒ (â€˜jawâ€™) Ñ2wc2 window: Ğ°Ğ½Ğ´Ñ€ĞµĞ¹ (â€˜
Andrejâ€™), Ğ±ĞµĞ´Ñ€Ğ¾ (â€˜hipâ€™), Ğ³Ğ¾Ğ´ (â€˜yearâ€™), ĞºĞ°Ğ¼ĞµÑ€Ğ° (â€˜cameraâ€™), Ğ»Ğ¸Ñ†Ğ¾ (â€˜faceâ€™), Ğ¼Ğ°Ğ»ÑŒÑ‡Ğ¸ĞºÂ (â€˜boyâ€™), Ğ¼Ğ°Ñ‚Ñ‡ (â€˜matchâ€™), Ğ½Ğ¾Ğ³Ğ° (â€˜legâ€™), Ğ½Ğ¾Ñ (â€˜noseâ€™), Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸ĞµÂ (â€˜fallâ€™), Ğ¿Ğ°Ğ»ĞµÑ†Â (â€˜fingerâ€™), Ğ¿Ğ¾Ğ±Ğ¾Ğ¸ (â€˜beatingâ€™), Ñ€Ğ°Ğ·(â€˜onceâ€™), Ñ€ĞµĞ±Ñ€Ğ¾ (â€˜ribâ€™), Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ (â€˜resultâ€™), Ñ€ÑƒĞºĞ° (â€˜armâ€™), Ñ‡ĞµĞ»ÑÑÑ‚ÑŒ (â€˜jawâ€™), ÑˆĞµÑ (â€˜neckâ€™)
The Cn notation is used to denote the cutoff threshold of n for syntactic model while the W
Cn denotes the cutoff threshold n for window-based model. For example, c10wc5 means that thresholds of 10 and 5 were applied to syntaxand window-based models respectively.
We have varied the frequency cutoff thresholds to examine the changes in correspondence between collocate sets built by using dependency-based and window-based approach. We have also compared the lists obtained using unequal thresholds.
3.5. Evaluation
The candidate sets extracted for each verb were ranked by PM
I, and only the top 20 collocates were selected. In order to evaluate the degree of correspondence between the lists obtained using syntaxand window-based methods, for each verb we have calculated two weighted intersection measures using the formula:
The impact of syntactic structure on verb-noun collocation extraction ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘(ğ‘¥ğ‘¥ğ‘¥ğ‘¥,ğ‘¦ğ‘¦ğ‘¦ğ‘¦) = logğ‘ƒğ‘ƒğ‘ƒğ‘ƒ(ğ‘¥ğ‘¥ğ‘¥ğ‘¥,ğ‘¦ğ‘¦ğ‘¦ğ‘¦)ğ‘ƒğ‘ƒğ‘ƒğ‘ƒ(ğ‘¥ğ‘¥ğ‘¥ğ‘¥) âˆ— ğ‘ƒğ‘ƒğ‘ƒğ‘ƒ(ğ‘¦ğ‘¦ğ‘¦ğ‘¦) ğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Š(ğ´ğ´ğ´ğ´;ğµğµğµğµ) = |ğ‘¥ğ‘¥ğ‘¥ğ‘¥ âˆˆ (ğ´ğ´ğ´ğ´ âˆ© ğµğµğµğµ)||ğ‘¥ğ‘¥ğ‘¥ğ‘¥ âˆˆ ğ´ğ´ğ´ğ´| ğ¹ğ¹ğ¹ğ¹1 =2 âˆ— ğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Š(ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘ğ‘ğ‘ğ‘ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤, ğ‘ ğ‘ ğ‘ ğ‘ ğ‘¦ğ‘¦ğ‘¦ğ‘¦ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘¥ğ‘¥ğ‘¥ğ‘¥) âˆ— ğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Š(ğ‘ ğ‘ ğ‘ ğ‘ ğ‘¦ğ‘¦ğ‘¦ğ‘¦ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘¥ğ‘¥ğ‘¥ğ‘¥,ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘ğ‘ğ‘ğ‘ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤)
ğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Š(ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘ğ‘ğ‘ğ‘ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤, ğ‘ ğ‘ ğ‘ ğ‘ ğ‘¦ğ‘¦ğ‘¦ğ‘¦ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘¥ğ‘¥ğ‘¥ğ‘¥) + ğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Š(ğ‘ ğ‘ ğ‘ ğ‘ ğ‘¦ğ‘¦ğ‘¦ğ‘¦ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘¥ğ‘¥ğ‘¥ğ‘¥,ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘ğ‘ğ‘ğ‘ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤) Let window be the set of collocations for a given verb extracted using the windowbased technique. Let syntax be the one extracted using the syntax-based method. The measure aims to describe how good the window-based list of nouns fits into the one extracted using the syntax-based representation. The measure is inversely the ratio of words from the syntax-based list, which are also presented in the list of words obtained by applying the window method. These measures can be thought of as Precision and Recall with syntax-based set treated as Key. As with Precision and Recall, the harmonic mean of two measures (
F-measure) was also computed using the standard formula:ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘(ğ‘¥ğ‘¥ğ‘¥ğ‘¥,ğ‘¦ğ‘¦ğ‘¦ğ‘¦) = logğ‘ƒğ‘ƒğ‘ƒğ‘ƒ(ğ‘¥ğ‘¥ğ‘¥ğ‘¥,ğ‘¦ğ‘¦ğ‘¦ğ‘¦)ğ‘ƒğ‘ƒğ‘ƒğ‘ƒ(ğ‘¥ğ‘¥ğ‘¥ğ‘¥) âˆ— ğ‘ƒğ‘ƒğ‘ƒğ‘ƒ(ğ‘¦ğ‘¦ğ‘¦ğ‘¦) ğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Š(ğ´ğ´ğ´ğ´;ğµğµğµğµ) = |ğ‘¥ğ‘¥ğ‘¥ğ‘¥ âˆˆ (ğ´ğ´ğ´ğ´ âˆ© ğµğµğµğµ)||ğ‘¥ğ‘¥ğ‘¥ğ‘¥ âˆˆ ğ´ğ´ğ´ğ´| ğ¹ğ¹ğ¹ğ¹1 =2 âˆ— ğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Š(ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘ğ‘ğ‘ğ‘ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤, ğ‘ ğ‘ ğ‘ ğ‘ ğ‘¦ğ‘¦ğ‘¦ğ‘¦ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘¥ğ‘¥ğ‘¥ğ‘¥) âˆ— ğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Š(ğ‘ ğ‘ ğ‘ ğ‘ ğ‘¦ğ‘¦ğ‘¦ğ‘¦ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘¥ğ‘¥ğ‘¥ğ‘¥,ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘ğ‘ğ‘ğ‘ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤)
ğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Š(ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘ğ‘ğ‘ğ‘ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤, ğ‘ ğ‘ ğ‘ ğ‘ ğ‘¦ğ‘¦ğ‘¦ğ‘¦ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘¥ğ‘¥ğ‘¥ğ‘¥) + ğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Šğ‘Š(ğ‘ ğ‘ ğ‘ ğ‘ ğ‘¦ğ‘¦ğ‘¦ğ‘¦ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘¥ğ‘¥ğ‘¥ğ‘¥,ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘ğ‘ğ‘ğ‘ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤) The comparison results are presented in 3.6. Results
The evaluation shows a moderate level of correspondence between the results obtained by comparing the two methods discussed. As W
I measures for different combinations of minimal combination frequency threshold shows (
Table 1) using distant threshold values (e. g. c10-wc2) leads to the worst results. According to the table, the best F1 is achieved using the threshold of 10 for both syntaxand windowbased algorithms, though the small size of resulting sets must be taken into account. The best W
I(syntax,window) is achieved by using cutoff threshold of 5 on syntaxand the one of 10 on window-based candidates.
Akinina Y. S., Kuznetsov I. O., Toldova S. Y.
value of W
I(syntax,window) averaged on all threshold combinations is significantly higher than the one of W
I(syntax,window). This reflects the fact that in many cases the majority of the words from syntax-based lists are included into the window-based lists, while the opposite is false.
Taking into account the starting hypothesis and presuming that the syntactic relations should give less noisy data, one could suggest that the collocation sets, obtained using window-based candidate list, would lack precision and introduce too much noisy data. However, the expert analysis shows that in many cases the collocates extracted by the window-based model are perfectly relevant to the task and should be treated as correct. Consider the following examples from sets obtained using frequency threshold of 5 in both algorithms. Matching words are shown in bold, and relevant words are underlined.
(3) Ğ·Ğ°Ğ±Ğ¸Ñ‚ÑŒ (â€˜kick, scoreâ€™)c5wc5 syntax: Ğ²Ğ¾Ñ€Ğ¾Ñ‚Ğ° (â€˜goalâ€™), Ğ³Ğ¾Ğ´ (â€˜yearâ€™), Ğ³Ğ¾Ğ» (â€˜goalâ€™), Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ° (â€˜headâ€™), (â€˜matchâ€™), Ğ¼Ğ¸Ğ½ÑƒÑ‚Ğ° (â€˜minuteâ€™), Ğ¼ÑÑ‡ (â€˜ballâ€™), ÑĞµĞ·Ğ¾Ğ½ (â€˜seasonâ€™), (â€˜alarmâ€™), Ñ„Ğ¾Ñ€Ğ²Ğ°Ñ€Ğ´ (â€˜forwardâ€™), ÑˆĞ°Ğ¹Ğ±Ğ° (â€˜puckâ€™) window: Ğ²Ğ¾Ñ€Ğ¾Ñ‚Ğ° (â€˜goalâ€™), Ğ³Ğ¾Ğ´ (â€˜yearâ€™), Ğ³Ğ¾Ğ» (â€˜goalâ€™), Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ° (â€˜headâ€™), ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° (â€˜teamâ€™), Ğ¼Ğ°Ñ‚Ñ‡ (â€˜matchâ€™), Ğ¼Ğ¸Ğ½ÑƒÑ‚Ğ° (â€˜minuteâ€™), Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚ (â€˜momentâ€™), Ğ¼ÑÑ‡ (â€˜ballâ€™), Ğ¿ĞµĞ½Ğ°Ğ»ÑŒÑ‚Ğ¸ (â€˜penaltyâ€™), Ğ¿Ğ¾Ğ»ÑƒĞ·Ğ°Ñ‰Ğ¸Ñ‚Ğ½Ğ¸Ğº (â€˜halfbackâ€™), ÑĞµĞ·Ğ¾Ğ½ (â€˜seasonâ€™), ÑĞ¼ĞµÑ€Ñ‚ÑŒÂ (â€˜deathâ€™), ÑĞ¾ÑÑ‚Ğ°Ğ² (â€˜membersâ€™), ÑÑ‡ĞµÑ‚ (â€˜scoreâ€™), Ñ‚Ğ°Ğ¹Ğ¼ (â€˜timeâ€™), Ñ‚Ñ€ĞµĞ²Ğ¾Ğ³Ğ° (â€˜alarmâ€™), Ñ‡ĞµĞ¼Ğ¿Ğ¸Ğ¾Ğ½Ğ°Ñ‚ (â€˜championshipâ€™), ÑˆĞ°Ğ¹Ğ±Ğ°(â€˜puckâ€™)4. Discussion
The analysis of the results shows that both methods share some common advantages and disadvantages, and the particular disadvantages of each method can be both due to experimental setting drawbacks and linguistic features of the texts. It turns out that, contrary to the expectations, the window-based method tends to extract some relevant verb-noun collocations, which are absent in the sets obtained by the syntax-based method. While the window-based approach also results in a higher level of noise, the syntax-based method suffers from narrowness of syntactic patterns used to extract collocation candidates. Our results show that using simple syntactic patterns is insufficient to model the semantic relations between predicate verbs and their arguments, which results in lower recall.
4.1. Common shortcomings
4.1.1. Corpus skewness
A common shortcoming of the lists obtained using both candidate extraction techniques is collocation specificity, which is related to the skewness of the source data. The texts in our corpus were obtained from news articles released in a one-year The impact of syntactic structure on verb-noun collocation extraction period, so the names of objects which were often mentioned in the media in that time span influence the statistics obtained from the whole corpus. That problem could be partially solved by using a larger and more representative corpus or recognizing and filtering out named entities.
(4) Ğ²Ğ¾Ğ·Ğ³Ğ»Ğ°Ğ²Ğ¸Ñ‚ÑŒ (â€˜be head ofâ€™)c10wc10 syntax: Ğ³Ğ¾Ğ´ (â€˜yearâ€™), Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³ (â€˜ratingâ€™), ÑĞ¾Ğ²ĞµÑ‚ (â€˜councilâ€™), ÑĞ¿Ğ¸ÑĞ¾Ğº (â€˜listâ€™) window: Ğ°Ğ»ĞµĞºÑĞ°Ğ½Ğ´Ñ€ (â€˜
Alexanderâ€™), Ğ²Ğ»Ğ°Ğ´Ğ¸Ğ¼Ğ¸Ñ€ (â€˜
Vladimirâ€™), Ğ³Ğ¾Ğ´ (â€˜yearâ€™), (â€˜groupâ€™), Ğ´Ğ¼Ğ¸Ñ‚Ñ€Ğ¸Ğ¹ (â€˜
Dmitryâ€™), ĞºĞ¾Ğ¼Ğ¸Ñ‚ĞµÑ‚ (â€˜committeeâ€™), Ğ¼ĞµĞ´Ğ²ĞµĞ´ĞµĞ² (â€˜
Medvedevâ€™), Ğ¾Ñ‚Ğ´ĞµĞ»ĞµĞ½Ğ¸Ğµ (â€˜departmentâ€™), Ğ¿Ğ°Ñ€Ñ‚Ğ¸Ñ (â€˜partyâ€™), Ğ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ğ¾ (â€˜governmentâ€™), Ğ¿Ñ€ĞµĞ·Ğ¸Ğ´ĞµĞ½Ñ‚ (â€˜presidentâ€™), Ğ¿ÑƒÑ‚Ğ¸Ğ½Â (â€˜
Putinâ€™), Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³ (â€˜ratingâ€™), Ñ€ÑƒĞºĞ¾Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒ (â€˜leaderâ€™), ÑĞµÑ€Ğ³ĞµĞ¹ (â€˜
Sergejâ€™), ÑĞ¾Ğ²ĞµÑ‚Â (â€˜councilâ€™), ÑĞ¿Ğ¸ÑĞ¾Ğº (â€˜listâ€™), ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ (â€˜boardâ€™), Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞº (â€˜manâ€™)4.1.2. Capturing the parts of other constructions
In some cases, the verb is syntactically related to a head of a fixed expression. In this case the collocations extracted by both methods will be invalid (see the examples below):(5) ÑĞ»ĞµĞ´Ğ¸Ñ‚ÑŒ (â€˜followâ€™) c5wc5 syntax: Ñ…Ğ¾Ğ´ (â€˜progressâ€™) window: Ñ…Ğ¾Ğ´ (â€˜progressâ€™), Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ğ°Ğ½Ğ¸Ğµ (â€˜votingâ€™)(6) (â€˜
As a member of the commission, he followed the progress of the voting at homeâ€™)4.2. Window method disadvantages
4.2.1. Capturing the dependant of a valid collocate
These cases are similar to the example (7), but here the collocation extracted by the syntactic method may be considered valid. At the same time, the window-based approach erroneously extracts its dependant:(7) Ğ¾Ñ‚ĞºĞ»Ğ¾Ğ½Ğ¸Ñ‚ÑŒ (â€˜declineâ€™): syntax: Ğ¶Ğ°Ğ»Ğ¾Ğ±Ğ° (â€˜complaintâ€™), Ğ¸ÑĞº (â€˜suitâ€™), Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ (â€˜propositionâ€™), window: Ğ¶Ğ°Ğ»Ğ¾Ğ±Ğ° (â€˜complaintâ€™), Ğ¸ÑĞº (â€˜suitâ€™), Ğ¼Ğ¾ÑĞºĞ²Ğ°Â (â€˜
Moscowâ€™), (â€˜propositionâ€™), ÑÑƒĞ´ (â€˜courtâ€™)(8) (â€˜
Yesterday the Moscow Arbitrage Court declined the suit of Rosimushestvo to JSCâ€¦â€™)
Akinina Y. S., Kuznetsov I. O., Toldova S. Y.
collocations extracted this way reflect the skewness of the corpus.
4.2.2. Frequent uninformative noise
The occurrence of high-frequency non-informative words like Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞº (â€˜manâ€™), Ğ³Ğ¾Ğ´ (â€˜yearâ€™), Ğ Ğ¾ÑÑĞ¸Ñ (â€˜
Russiaâ€™) is a prominent feature of the collocation lists extracted by window-based method. They may be linguistically unrelated, as Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞº in (9):(9) Ğ¾Ñ‚Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ (â€˜let outâ€™)c5wc5 syntax: Ğ·Ğ°Ğ»Ğ¾Ğ³ (â€˜bailâ€™), Ğ¸Ğ³Ñ€Ğ¾Ğº (â€˜playerâ€™), ÑĞ²Ğ¾Ğ±Ğ¾Ğ´Ğ° (â€˜freedomâ€™), ÑÑƒĞ´ (â€˜courtâ€™) window: Ğ·Ğ°Ğ»Ğ¾Ğ³ (â€˜bailâ€™), Ğ¸Ğ³Ñ€Ğ¾Ğº (â€˜playerâ€™), ÑĞ²Ğ¾Ğ±Ğ¾Ğ´Ğ° (â€˜freedomâ€™), ÑÑƒĞ´ (â€˜courtâ€™), Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞº (â€˜manâ€™)(10) (â€˜
Many of them were let out, but several people spent all night at the police stationâ€™)
It may also be a member of a regular circumstantial construction as Ğ³Ğ¾Ğ´ in (11):(11) ÑĞ´Ğ°Ñ‚ÑŒ (â€˜passâ€™)c5wc5 syntax: ÑĞºĞ·Ğ°Ğ¼ĞµĞ½ (â€˜examâ€™) window: Ğ³Ğ¾Ğ´ (â€˜yearâ€™), ÑĞºĞ·Ğ°Ğ¼ĞµĞ½ (â€˜examâ€™)(12) (â€˜
Is this the house that has already been commissioned by 2005?â€™)
This type of nouns in the top of the window lists is due to the general frequency of expressions of an event time in a clause (itâ€™s also true for some other semantic relations). For instance, the collocation Ğ³Ğ¾Ğ´ (â€˜yearâ€™) is found only by window-based method in 137 verbs out of 548 within the cutoff threshold of 5. We suppose that an additional procedure of filtering such cases could increase the degree of syntaxbased and window-based lists overlapping.
4.3. Syntax-based method shortcomings
Although we have analyzed only finite verb forms in order to reduce syntactic complexity, there are still many issues related to describing the syntactic construction in which semantic relatedness can be expressed. In many cases, a related noun was not captured by the syntax-based candidate extraction algorithm due to the absence of the direct syntactic relationship to the verb in a sentence. Common cases include relative clauses, argument coordination and object pronominalization.
The impact of syntactic structure on verb-noun collocation extraction 4.3.1. Relative clauses
One common case which is not taken into account by our syntax-based model is the one when the verb is located in a relative clause as in the following example:(13) (â€˜
After the lecture that he read us at schoolâ€¦â€™)
The window-based model was able to extract the candidate Ğ»ĞµĞºÑ†Ğ¸Ğ¸ (lectures) + Ğ¿Ñ€Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ (read) while the power of our syntax pattern-based method was insufficient to capture the semantic relatedness between these two words. In cases when the amount of such constructions is high, this issue can influence the overall corpus statistics, e. g.:(14) Ğ¿Ñ€Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ (â€˜readâ€™) c10wc10 syntax: Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚ (â€˜
Internetâ€™), ĞºĞ½Ğ¸Ğ³Ğ° (â€˜bookâ€™) window: Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚ (â€˜
Internetâ€™), ĞºĞ½Ğ¸Ğ³Ğ° (â€˜bookâ€™), Ğ»ĞµĞºÑ†Ğ¸Ñ (â€˜lectureâ€™)4.3.2. Argument coordination
Another syntactic relation type that should be taken into account is coordination. The parser that we used is based on the framework where the dependency relation between a verb and its coordinated arguments is drawn to the first of these arguments, followed by a chain dependency through a conjunction. See Figure 16, where the verb â€œĞ²Ñ‹ĞµÑ…Ğ°Ğ»Ğ¸â€ (go, leave) is connected only to the first argument Ğ¿Ğ¾Ğ»Ğ¸Ñ†ĞµĞ¹ÑĞºĞ¸Ğµ (policemen). That first argument is then connected to the second one, ÑĞ¾Ñ‚Ñ€ÑƒĞ´Ğ½Ğ¸ĞºĞ¸ (officials) with the conjunction Ğ¸ (and).
(15) Ğ²Ñ‹ĞµÑ…Ğ°Ñ‚ÑŒ (â€˜drive off)c5wc5 syntax: Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»ÑŒ (â€˜carâ€™), Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ° (â€˜groupâ€™), Ğ¼ĞµÑÑ‚Ğ¾ (â€˜placeâ€™), Ğ¿Ğ¾Ğ»Ğ¾ÑĞ° (â€˜laneâ€™), (â€˜onceâ€™) window: Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»ÑŒ (â€˜carâ€™), Ğ³Ğ»Ğ°Ğ²Ğ° (â€˜â€™head), Ğ³Ğ¾Ğ´ (â€˜yearâ€™), Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ° (â€˜groupâ€™), (â€˜trafficâ€™), Ğ´Ğ¾Ğ¼ (â€˜houseâ€™), Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ° (â€˜carâ€™), Ğ¼ĞµÑÑ‚Ğ¾ (â€˜placeâ€™), Ğ¾Ğ±Ğ»Ğ°ÑÑ‚ÑŒ (â€˜regionâ€™), Ğ¿Ğ¾Ğ»Ğ¸Ñ†Ğ¸Ñ (â€˜policeâ€™), Ğ¿Ğ¾Ğ»Ğ¾ÑĞ° (â€˜laneâ€™), Ğ¿Ñ€Ğ¾Ğ¸ÑÑˆĞµÑÑ‚Ğ²Ğ¸Ğµ (â€˜accidentâ€™), ÑĞ¾Ñ‚Ñ€ÑƒĞ´Ğ½Ğ¸Ğº (â€˜officialâ€™), ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ (â€˜boardâ€™), Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞº (â€˜manâ€™)(16) (â€˜
The police and the officials of the recruiting office drove off on their trackâ€™)
Note that the window-based method succeeds to extract collocations in some of these cases.
4.3.3. Argument pronominalization
The final drawback of the syntactic method which is worth mentioning is that our model lacks co-reference information. In many cases, the core arguments of a verb Akinina Y. S., Kuznetsov I. O., Toldova S. Y.
the subject and object) are substituted by a pronoun. When the antecedent is in the same sentence, it still can be located by the window-based approach, but the syntax-based candidate extractor fails to identify the candidate due to the lack of coreference information, as in the following example:(17) ĞµÑ…Ğ°Ñ‚ÑŒ (â€˜go, travelâ€™)c5wc5 syntax: Ğ²Ğ°Ğ³Ğ¾Ğ½ (â€˜carriageâ€™), Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ° (â€˜carâ€™) window: Ğ°Ğ²Ñ‚Ğ¾Ğ±ÑƒÑ (â€˜busâ€™), Ğ²Ğ°Ğ³Ğ¾Ğ½ (â€˜carriageâ€™), Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒ (â€˜driverâ€™), Ğ³Ğ¾Ğ´ (â€˜yearâ€™), Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ° (â€˜carâ€™), Ğ¼Ğ¸Ğ½ÑƒÑ‚Ğ° (â€˜minuteâ€™), Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞº (â€˜manâ€™)(18) (â€˜
Here he is, the Average Moscow Driver, traveling in his â€œdevyatkaâ€ (car model)â€™)
However, the antecedent is not always located in the same sentence. In this case, both methods fail to identify collocation candidates. Improving the preprocessor by adding a co-reference resolution engine should increase the overall numbers of collocation candidates and soften the consequences of the fact that some collocate types tend to be pronominalized more often than the others.
4.4. Typical argument extraction
Although some researches use (or assume the need of use of) syntactic information to extract typical arguments from the collocation lists or to filter them out, our study shows that both methods are suitable for the extraction of such verbnoun constructions. Both typical subjects and typical objects can be retrieved by either method, see examples below:
Typical subjects(19) Ğ°Ñ€ĞµÑÑ‚Ğ¾Ğ²Ğ°Ñ‚ÑŒ (â€˜arrestâ€™)c10wc10 syntax: Ğ¿Ğ¾Ğ»Ğ¸Ñ†Ğ¸Ñ (â€˜policeâ€™), ÑÑƒĞ´ (â€˜courtâ€™) window: Ğ³Ğ¾Ğ´ (â€˜yearâ€™), Ğ¿Ğ¾Ğ»Ğ¸Ñ†Ğ¸Ñ (â€˜policeâ€™), ÑÑƒĞ´(â€˜courtâ€™)
Typical objects(20) ÑĞ»Ğ¾Ğ¼Ğ°Ñ‚ÑŒ (â€˜breakâ€™)c10wc10 syntax: Ñ€ÑƒĞºĞ° (â€˜armâ€™), Ğ½Ğ¾Ğ³Ğ° (â€˜legâ€™) window: Ñ€ÑƒĞºĞ° (â€˜armâ€™), Ğ½Ğ¾Ğ³Ğ° (â€˜legâ€™)
The possible way to take into consideration the particular type of arguments in the window-based method is to use the more granulated noun morphological features such as cases. However the distinguishing between these two cases or, in more complex cases, between subject and object collocates within the list of one verb was beyond the scope of our research.
The impact of syntactic structure on verb-noun collocation extraction 5. Conclusion
In our study we have compared two methods of building collocation candidate lists within the framework of verb-noun collocation extraction. We have conducted an experiment on extracting and ranking collocation candidates from a large preprocessed corpus of news data using two different candidate extraction methods. An automatic comparison of collocation lists obtained using window-based and syntax-based candidate extractors has shown only a moderate level of correspondence. The detailed analysis of the comparison results makes it possible to identify common advantages and disadvantages of both methods.
In general, the window-based extractor seems to outperform the one based on a syntax-driven approach in terms of recall. Our results show that the simple syntax collocation model which only takes direct and prepositional verb-noun dependencies into account is not powerful enough. It is due to two basic phenomena. The first one is that there are a sufficient number of cases when the semantically related nouns are not immediate dependant of a verb. Moreover they can occur close to a verb but in another clause. The second one is the anaphora phenomena. The arguments of a verb can be pronominalized or omitted in real discourse especially as far as subject N
Ps is concerned. Adding special modules for syntax-based collocation extraction for treating these phenomena might improve the quality of the syntax-based method.
